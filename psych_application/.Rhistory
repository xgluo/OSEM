TumorRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
TumorCov <- temp$Coverage
# Extract information for normal sample
temp <- d.Normal[d.Normal$Position == pos,]
NormalRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
Rb <- as.character(temp$Reference)
NormalCov <- temp$Coverage
rm(temp)
# Determine the possible variant allele(s) using tumor sample:
# An allele is a variant allele if it is different from the reference allele
# and it appears more often than all other non-reference alleles.
# In the case of ties, we store all the tie alleles.
candidates <- sapply(setdiff(c("A","C","G","T"),Rb), function(a) sum(TumorRb == a))
if (sum(candidates) == 0) {
# If none of the non-reference alleles appear in the read bases,
# it means there are no variants at this position, simply return an empty dataframe
return(res)
} else {
variants <- names(which(candidates == max(candidates)))
varCounts <- rep(max(candidates),length(variants))
}
# For each variant allele, create a contingency table and compute the p-value.
# Append a new row to the output dataframe
for (i in 1:length(variants)) {
# Count the number of occurances of the ith variant in the normal read bases
varCountNorm <- sum(NormalRb == variants[i])
# Contingency table
contTable <- matrix(c(varCounts[i],varCountNorm,
TumorCov - varCounts[i],NormalCov - varCountNorm),
nrow = 2, ncol = 2,
dimnames = list(c("Tumor","Normal"),
c("No.Variant","No.Other")))
res[i,] <- c(pos,
Rb,
variants[i],
fisher.test(contTable,alternative = "greater")$p.value)
}
res$P_value <- as.numeric(res$P_value)
return(res)
}
})
# Run through all positions
res <- parLapply(cl,d.Tumor$Position,function(i) varscan2(i))
# res <- data.frame(matrix(nrow = 0,ncol=4))
# for (i in 1:nrow(d.Tumor)) {
#   res <- rbind(res,varscan2(d.Tumor$Position[i]))
# }
load("/Users/luox/Documents/Projects/OSEM/simulations_20210510/logloss.RData")
head(res)
stopCluster(cl)
head(res)
dim(results)
dim(results["OSEM",,])
hist(apply(results["OSEM",,], 2, min))
hist(apply(results["BGe",,], 2, min))
mean(apply(results["OSEM",,], 2, min))
mean(apply(results["BGe",,], 2, min))
mean(apply(results["BDe",,], 2, min))
mean(apply(results["pcart",,], 2, min))
mean(apply(results["BGe2",,], 2, min))
?glmnet
?cv.glmnet
head(res)
temp <- simplify2array(res)
dim(temp)
dim(t(temp))
temp <- t(temp)
temp[1,]
res2 <- t(simplify2array(res))
class(res2)
dim(res2)
res[[1]]
res2 <- data.frame(matrix(nrow = 0,ncol=4))
for (i in c(1:length(res))) {
res2 <- rbind(res2, res[[i]])
}
rm(temp)
# Report the SNVs at 10% significance level
res2 <- sapply(res, function(x) x[x$P_value < 0.1,])
dim(res2)
dim(res)
res[[1]]
x <- res[[1]]
x[x$P_value < 0.1,]
# Report the SNVs at 10% significance level
res2 <- matrix(NA, nrow = 0, ncol = 4)
length(res)
for (i in c(1:length(res))) {
x <- res[[i]]
res2 <- rbind(res2, x[x$P_value < 0.1,])
}
dim(res2)
res2
res2 <- matrix(NA, nrow = 0, ncol = 4)
for (i in c(1:length(res))) {
x <- res[[i]]
res2 <- rbind(res2, x)
}
cl
# Report the SNVs at 10% significance level
res2 <- parSapply(cl, res, function(x) x[x$P_value<0.1,])
stopCluster(cl)
res2 <- matrix(NA, nrow = 0, ncol = 4)
for (i in c(1:length(res))) {
x <- res[[i]]
res2 <- rbind(res2, x[x$P_value < 0.1,])
}
res2
?simplify2array
length(res)
?as.array
adj.pvalues <- sapply(res, function(x) x$P_value)
dim(adj.pvalues)
length(adj.pvalues)
adj.pvalues[[1]]
length(simplify2array(adj.pvalues))
?parSapply
?do.call
res2 <- do.call("rbind",res)
dim(res2)
# Report the SNVs at 10% significance level
str(res2[res2$P_value<0.1,])
# Report the SNVs at 10% significance level after FDR correction
str(res2[p.adjust(res2$P_value,method = "fdr")<0.1,])
?mclapply
library(parallel)
d.Normal <- read.table("Normal_pileup.txt",header = TRUE)
d.Tumor <- read.table("Tumor_pileup.txt",header = TRUE)
par(mfrow = c(1,2))
hist(d.Normal$Coverage,
main = "Normal Tissue Sample",xlab="Coverage")
hist(d.Tumor$Coverage,main = "Tumor Sample",xlab="Coverage")
head(d.Normal)
library(parallel)
d.Normal <- read.table("Normal_pileup.txt",header = TRUE)
d.Tumor <- read.table("Tumor_pileup.txt",header = TRUE)
par(mfrow = c(1,2))
hist(d.Normal$Coverage,
main = "Normal Tissue Sample",xlab="Coverage")
hist(d.Tumor$Coverage,main = "Tumor Sample",xlab="Coverage")
##' Function: varscan2
##' For each position and each possible variant allele,
##' we first construct a 2-by-2 contingency table of the following form:
##'        | No. of variant alleles | No. of all other alleles
##' ============================================================
##' Tumor  |                        |
##' Normal |                        |
##' Then, we calculate the p-value using a right-tailed Fisher's Exact Test with
##' the alternative hypothesis being "greater".
##' @param pos: Position of the reference base
##' @return a dataframe with four columns: Position, Reference, Variant, P-value
varscan2 <- function(pos, d.Normal, d.Tumor) {
# Initialize the final output dataframe
res <- data.frame(matrix(nrow = 0,ncol=4))
colnames(res) <- c("Position", "Reference", "Variant", "P_value")
# Extract information for tumor sample
temp <- d.Tumor[d.Tumor$Position == pos,]
TumorRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
TumorCov <- temp$Coverage
# Extract information for normal sample
temp <- d.Normal[d.Normal$Position == pos,]
NormalRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
Rb <- as.character(temp$Reference)
NormalCov <- temp$Coverage
rm(temp)
# Determine the possible variant allele(s) using tumor sample:
# An allele is a variant allele if it is different from the reference allele
# and it appears more often than all other non-reference alleles.
# In the case of ties, we store all the tie alleles.
candidates <- sapply(setdiff(c("A","C","G","T"),Rb), function(a) sum(TumorRb == a))
if (sum(candidates) == 0) {
# If none of the non-reference alleles appear in the read bases,
# it means there are no variants at this position, simply return an empty dataframe
return(res)
} else {
variants <- names(which(candidates == max(candidates)))
varCounts <- rep(max(candidates),length(variants))
}
# For each variant allele, create a contingency table and compute the p-value.
# Append a new row to the output dataframe
for (i in 1:length(variants)) {
# Count the number of occurances of the ith variant in the normal read bases
varCountNorm <- sum(NormalRb == variants[i])
# Contingency table
contTable <- matrix(c(varCounts[i],varCountNorm,
TumorCov - varCounts[i],NormalCov - varCountNorm),
nrow = 2, ncol = 2,
dimnames = list(c("Tumor","Normal"),
c("No.Variant","No.Other")))
res[i,] <- c(pos,
Rb,
variants[i],
fisher.test(contTable,alternative = "greater")$p.value)
}
res$P_value <- as.numeric(res$P_value)
return(res)
}
library(parallel)
d.Normal <- read.table("Normal_pileup.txt",header = TRUE)
library(parallel)
d.Normal <- read.table("Normal_pileup.txt",header = TRUE)
d.Tumor <- read.table("Tumor_pileup.txt",header = TRUE)
par(mfrow = c(1,2))
hist(d.Normal$Coverage,
main = "Normal Tissue Sample",xlab="Coverage")
hist(d.Tumor$Coverage,main = "Tumor Sample",xlab="Coverage")
##' Function: varscan2
##' For each position and each possible variant allele,
##' we first construct a 2-by-2 contingency table of the following form:
##'        | No. of variant alleles | No. of all other alleles
##' ============================================================
##' Tumor  |                        |
##' Normal |                        |
##' Then, we calculate the p-value using a right-tailed Fisher's Exact Test with
##' the alternative hypothesis being "greater".
##' @param pos: Position of the reference base
##' @return a dataframe with four columns: Position, Reference, Variant, P-value
varscan2 <- function(pos, d.Normal, d.Tumor) {
# Initialize the final output dataframe
res <- data.frame(matrix(nrow = 0,ncol=4))
colnames(res) <- c("Position", "Reference", "Variant", "P_value")
# Extract information for tumor sample
temp <- d.Tumor[d.Tumor$Position == pos,]
TumorRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
TumorCov <- temp$Coverage
# Extract information for normal sample
temp <- d.Normal[d.Normal$Position == pos,]
NormalRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
Rb <- as.character(temp$Reference)
NormalCov <- temp$Coverage
rm(temp)
# Determine the possible variant allele(s) using tumor sample:
# An allele is a variant allele if it is different from the reference allele
# and it appears more often than all other non-reference alleles.
# In the case of ties, we store all the tie alleles.
candidates <- sapply(setdiff(c("A","C","G","T"),Rb), function(a) sum(TumorRb == a))
if (sum(candidates) == 0) {
# If none of the non-reference alleles appear in the read bases,
# it means there are no variants at this position, simply return an empty dataframe
return(res)
} else {
variants <- names(which(candidates == max(candidates)))
varCounts <- rep(max(candidates),length(variants))
}
# For each variant allele, create a contingency table and compute the p-value.
# Append a new row to the output dataframe
for (i in 1:length(variants)) {
# Count the number of occurances of the ith variant in the normal read bases
varCountNorm <- sum(NormalRb == variants[i])
# Contingency table
contTable <- matrix(c(varCounts[i],varCountNorm,
TumorCov - varCounts[i],NormalCov - varCountNorm),
nrow = 2, ncol = 2,
dimnames = list(c("Tumor","Normal"),
c("No.Variant","No.Other")))
res[i,] <- c(pos,
Rb,
variants[i],
fisher.test(contTable,alternative = "greater")$p.value)
}
res$P_value <- as.numeric(res$P_value)
return(res)
}
# Run through all positions
res <- mclapply(d.Tumor$Position, varscan2, d.Normal, d.Tumor, mc.cores = detectCores())
pos <- 247280
res <- data.frame(matrix(nrow = 0,ncol=4))
colnames(res) <- c("Position", "Reference", "Variant", "P_value")
# Extract information for tumor sample
temp <- d.Tumor[d.Tumor$Position == pos,]
TumorRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
TumorCov <- temp$Coverage
# Extract information for normal sample
temp <- d.Normal[d.Normal$Position == pos,]
NormalRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
Rb <- as.character(temp$Reference)
NormalCov <- temp$Coverage
rm(temp)
# Determine the possible variant allele(s) using tumor sample:
# An allele is a variant allele if it is different from the reference allele
# and it appears more often than all other non-reference alleles.
# In the case of ties, we store all the tie alleles.
candidates <- sapply(setdiff(c("A","C","G","T"),Rb), function(a) sum(TumorRb == a))
candidates
pos <- 392637
res <- data.frame(matrix(nrow = 0,ncol=4))
colnames(res) <- c("Position", "Reference", "Variant", "P_value")
# Extract information for tumor sample
temp <- d.Tumor[d.Tumor$Position == pos,]
TumorRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
TumorCov <- temp$Coverage
# Extract information for normal sample
temp <- d.Normal[d.Normal$Position == pos,]
NormalRb <- toupper(unlist(strsplit(as.character(temp$Read_bases),"")))
Rb <- as.character(temp$Reference)
NormalCov <- temp$Coverage
rm(temp)
# Determine the possible variant allele(s) using tumor sample:
# An allele is a variant allele if it is different from the reference allele
# and it appears more often than all other non-reference alleles.
# In the case of ties, we store all the tie alleles.
candidates <- sapply(setdiff(c("A","C","G","T"),Rb), function(a) sum(TumorRb == a))
if (sum(candidates) == 0) {
# If none of the non-reference alleles appear in the read bases,
# it means there are no variants at this position, simply return an empty dataframe
return(res)
} else {
variants <- names(which(candidates == max(candidates)))
varCounts <- rep(max(candidates),length(variants))
}
candidates
variants
i = 1
varCountNorm <- sum(NormalRb == variants[i])
# Contingency table
contTable <- matrix(c(varCounts[i],varCountNorm,
TumorCov - varCounts[i],NormalCov - varCountNorm),
nrow = 2, ncol = 2,
dimnames = list(c("Tumor","Normal"),
c("No.Variant","No.Other")))
contTable
Rb
sapply(c("A","C","G","T"), function(a) sum(TumorRb == a))
sapply(c("A","C","G","T"), function(a) sum(NormalRb == a))
TumorRb
sum(TumorRb == ".")
sum(TumorRb == ",")
sum(NormalRb == ".")
sum(NormalRb == ",")
14+20
NormalRb
TumorCov
NormalCov
contTable
contTable[1,1] <- 4
fisher.test(contTable,alternative = "greater")$p.value
dim(results)
load("/Users/luox/Documents/Projects/OSEM/simulations_20210510/logloss.RData")
dim(results)
test <- adply(results,c(1,2))
library(ggplot2)
library(gridExtra)
library(plyr)
library(ggpubr)
library(latex2exp)
library(dplyr)
test <- adply(results,c(1,2))
head(test)
test <- adply(results,c(1,3))
head(test)
test <- adply(results,c(1,2,3))
head(test)
test <- adply(results,c(2,3))
head(test)
test <- adply(results,c(1))
head(test)
test <- adply(results,c(1,3))
head(test)
test <- adply(results,c(1,2,3))
head(test)
ggplot(test, aes(x = X2, y = V1, fill = X1)) +
geom_boxplot()
ggplot(test, aes(x = X2, y = V1, fill = X1)) +
geom_violin()
ggplot(test, aes(x = X2, y = V1, fill = X1)) +
geom_point()
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point()
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot() +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
dimnames(results)
dimnames(results)[[1]] <- c("OSEM", "BDe", "BGe", "disc.BGe", "pcart")
test <- adply(results,c(1,2,3))
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
dimnames(results)[[1]] <- c("OSEM", "BDe", "disc.BGe", "BGe", "pcart")
test <- adply(results,c(1,2,3))
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  + geom_abline(V1 ~ X2) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  + geom_abline(aes(V1 ~ X2)) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  + geom_abline(aes(y ~ x)) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  + stat_smooth(method = "lm") +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_boxplot()  + geom_smooth(method = "lm", fill = NA) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point()  + geom_smooth(method = "lm", fill = NA) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point()  + geom_abline() +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
test <- adply(results,c(1,2,3))
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point()  + geom_abline(group = X1) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point()  + geom_abline(group = X1,data = test) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
head(test)
test %>% mean
dim(results)
test2 <- adply(apply(results, c(1,2), mean))
test2 <- adply(apply(results, c(1,2), mean), c(1,2))
head(test2)
dim(apply(results, c(1,2), mean))
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point()  + geom_path(mapping = aes(x = X2, y = V1, group = X1, colour = factor(X1)),
data = test2,
size = 1) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point()  + geom_path(mapping = aes(x = X2, y = V1, group = X1, colour = factor(X1)),
data = test2) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
ggplot(test, aes(x = X2, y = V1, color = X1)) +
geom_point(alpha = 0.5)  + geom_path(mapping = aes(x = X2, y = V1, group = X1, colour = factor(X1)),
data = test2) +
labs(color = "Method") +
ylab("log loss on test data") + xlab("penalty index")
comparePatterns(E.G4,trueDAG)
setwd("~/Documents/Projects/OSEM/OSEM/R/")
# Major file containing the OSEM algorithm
source("ordinalScore.R")
# Modify some of the existing functions in the BiDAG package to accommodate our user-defined functions
insertSource("spacefns.R",package = "BiDAG")
insertSource("usrscorefns.R",package = "BiDAG")
setwd("~/Documents/Projects/BiDAG/R")
insertSource("scoreagainstdag.R",package = "BiDAG")
# Load data
setwd("~/Documents/Projects/OSEM/OSEM/psych_application/")
load("OCDRogers.RData")
n <- ncol(datRogers)
N <- nrow(datRogers)
# Create training and test set for validation set approach (80% train/20% test)
test <- sample(1:N, N/5, replace=FALSE)
train <- (-test)
train.data <- datRogers[train,]
test.data <- datRogers[test,]
datRogers_levels <- apply(datRogers, 2, function(x) length(unique(x)))
BGE <- scoreparameters("bge", train.data, bgepar = list(am = 0.05))
BGEfit <- iterativeMCMC(BGE)
BGEfit <- iterativeMCMC(BGE)
# Required packages
library(BiDAG)
library(pcalg)
BGEfit <- iterativeMCMC(BGE)
# BGe
BGE <- scoreparameters("bge", train.data, bgepar = list(am = 0.05))
BGEfit <- iterativeMCMC(BGE)
# Required packages
library(BiDAG)
library(pcalg)
setwd("~/Documents/Projects/OSEM/OSEM/R/")
# Major file containing the OSEM algorithm
source("ordinalScore.R")
# Modify some of the existing functions in the BiDAG package to accommodate our user-defined functions
insertSource("spacefns.R",package = "BiDAG")
insertSource("usrscorefns.R",package = "BiDAG")
setwd("~/Documents/Projects/BiDAG/R")
insertSource("scoreagainstdag.R",package = "BiDAG")
# Load data
setwd("~/Documents/Projects/OSEM/OSEM/psych_application/")
load("OCDRogers.RData")
n <- ncol(datRogers)
N <- nrow(datRogers)
# Create training and test set for validation set approach (80% train/20% test)
test <- sample(1:N, N/5, replace=FALSE)
train <- (-test)
train.data <- datRogers[train,]
test.data <- datRogers[test,]
datRogers_levels <- apply(datRogers, 2, function(x) length(unique(x)))
# OSEM
# BGe
BGE <- scoreparameters("bge", train.data, bgepar = list(am = 0.05))
BGEfit <- iterativeMCMC(BGE)
test <- sample(1:N, N/5, replace=FALSE)
train <- (-test)
train.data <- datRogers[train,]
test.data <- datRogers[test,]
datRogers_levels <- apply(datRogers, 2, function(x) length(unique(x)))
# BGe
BGE <- scoreparameters("bge", train.data, bgepar = list(am = 0.05))
BGEfit <- iterativeMCMC(BGE)
